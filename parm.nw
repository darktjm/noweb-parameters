\documentclass{article}
\usepackage{noweb}
\usepackage{hyperref}

\noweboptions{smallcode,longchunks}

\begin{document}

\title{Parameterized Chunks for noweb}
\author{Thomas J. Moore}
\date{Version 1.01\\23 July, 2013}
\maketitle

This document is placed in the public domain by its author.

\tableofcontents

\section{Introduction}

I like to consolidate code as much as possible.  I do this in C using
either subroutines or preprocessor macros.  The macros are more useful
when the number of inputs and/or outputs are large, or using a macro
is significantly faster.  The subroutines cannot even be used when
doing something like defining a large number of similar symbols, or
providing a more convenient way to define data tables.  The
preprocessor can usually accomplish what I need, but the price is that
the debugger cannot debug code defined by the preprocessor.  In
addition, there are some languages which lack a preprocessor.  As
such, the original Web system had macros with arguments, and I would
like something similar.

I propose the following syntax changes:

\begin{itemize}

\item A chunk name used in a chunk definition line may contain
parameter definitions in parentheses.  All parameter names begin with
an at-sign (@).  The only characters forbidden in parameter names are
close-parentheses and invalid NoWeb syntax.  Thus the parameter name
is terminated by its closing parenthesis.  Parameter definition syntax
within in-line code is ignored.

For example:
\begin{quote}
\begin{verbatim}
@<<macro (@arg1) with -(@arg2)- (but not @[[(@arg3)]])>>=
text
@@
\end{verbatim}
\end{quote}

The parameters are [[@arg1]] and [[@arg2]].

\item No chunk name may begin with an at-sign (@).  That is, the names
starting with an at-sign are reserved for parameter names.

\item Chunk references beginning with an at-sign (@) expand to the
parameter with that name, as defined by the closest parent taking a
parameter of that name.  When weaved, such references are not linked
anywhere, and they are not added to the index.  When tangled, the
[[-L]] option is ignored.

For example:

\begin{quote}
\begin{verbatim}
@<<macro (@arg)>>=
text @<<@arg>>
@<<other>>
@@
@<<macro2 (@arg)>>=
text2 @<<@arg>>
@<<other>>
@@
@<<other>>=
@<<@arg>>
@@
\end{verbatim}
\end{quote}

When expanded within [[macro]], both [[@arg]] and [[other]] will
expand using [[macro]]'s argument.  When expanded within [[macro2]],
both [[@arg]] and [[other]] will expand using [[macro2]]'s argument.

\item A chunk reference consisting of the name of a chunk taking
parameters, with all parameter references replaced by NoWeb in-line
code segments, represents an expansion of the reference with the
parameters taking the value of the code within the in-line code
segments in their respective positions.  No expansion is done within
the code segments except for parameter references; these may be used
to pass parameters on to another macro.

For example:

\begin{quote}
\begin{verbatim}
@<<macro (@arg)>>=
text @<<@arg>>
@@
@<<macro2 (@arg)>>=
@<<macro @[[and @<<@arg>>]]>>
@@
@<<macro3 (@arg)>>=
@<<macro4>>
@@
@<<macro4>>=
can reference @<<@arg>> of macro3.
@@
@<<caller>>=
text @<<macro @[[text2]]>> @<<macro2 @[[text3]]>>
@<<macro3 @[[text4]]>>
@@
\end{verbatim}
\end{quote}

The [[caller]] chunk expands to

\begin{quote}
\begin{verbatim}
text text text2 text and text3
can reference text4 of macro3.
\end{verbatim}
\end{quote}

\item When more than one parameterized chunk could be used to replace
a reference, the one with the least parameter replacements is chosen.
For equal numbers, the one which does not contain the earliest
parameter replacement is chosen.

For example:

\begin{quote}
\begin{verbatim}
@<<macro (@arg1) and (@arg2)>>=
text @<<@arg1>> blah @<<@arg2>>
@@
@<<macro @[[1]] and (@arg)>>=
text blah blah @<<@arg>>
@@
@<<macro (@arg) and @[[2]]>>=
text blah blah blah @<<@arg>>
@@
@<<*>>=
@<<macro @[[a]] and @[[b]]>> -- one blah
@<<macro @[[1]] and @[[b]]>> -- two blahs
@<<macro @[[a]] and @[[2]]>> -- three blahs
@<<macro @[[1]] and @[[2]]>> -- two blahs and a warning
@@
\end{verbatim}
\end{quote}

\item For literal text matching, all passed-on variable references are
expanded first.

For example:

\begin{quote}
\begin{verbatim}
@<<macro (@arg)>>=
1 @<<@arg>>
@@
@<<macro @[[x y]]>>=
1 z
@@
@<<macro2 (@arg)>>=
@<<macro [[x @<<@arg>>]]>>
@@
@<<*>>=
@<<macro2 @[[x]]>> -- 1 x x
@<<macro2 @[[y]]>> -- 1 z
@@
\end{verbatim}
\end{quote}

\end{itemize}

\section{Tangling}

Rather than create an entirely new tangler, the NoWeb pipeline is
used.  Also, rather than modifying the NoWeb tangler, a filter is
created.  A filter is less efficient than simply replacing the
tangler, but it is compatible with both NoWeb 2 and 3.

While I would prefer to write this in C, there are valid arguments for
writing this in perl instead%
\footnote{On the other hand, C++ provides most of the needed
functionality in the standard template library, so perhaps one day I
will rewrite this in C++.}%
.  If I use C, I will either have to develop some string processing
and hash table routines, or I will have to use an existing library,
such as GLib.  While I am not too concerned about non-POSIX systems,
regular expression support is not necessarily present on non-POSIX
systems, either, unless something like GLib is used.  The problem with
GLib is that it is not as commonly available as perl, and is also not
consistently easy to find (e.g. [[pkg-config]] is not universally
available, and the token for [[GLib]] is inconsistent), and requires
work to ensure that the correct versions are available.  In contrast,
as long as I do not use any esoteric libraries or advanced features,
perl should work with most installations without too much trouble.

%\lstset{language=perl}
<<Common Perl Prefix>>=
#!/bin/sh
#!perl
# GENERATED FILE:  DO NOT EDIT OR READ THIS FILE
# Instead, read or edit the NoWeb file(s) from which this was generated.
eval 'exec perl -x -f "$0" "$@"'
  if 0;

use strict;
@

<<nt-parm>>=
<<Common Perl Prefix>>

<<[[nt-parm]] local definitions>>

<<Gather code chunks from NoWeb pipeline>>

<<Mangle and dump pipeline>>
@

Tangling a parameterized chunk is done by duplicating the chunk
definition for every unique reference, replacing parameters as
necessary.  Since the above definition allows chunks expanded within
the parameterized chunk (recursively) to also expand the same
parameters, they may need to be duplicated as well.  Chunk references
in the unduplicated code do not need to be modified, since the newly
created chunk names match their usage.  In fact, the original input
can be safely dumped unmodified to the output.

All definition text is slurped into a single array ([[@notext]]).
Since we only care about chunk definition and reference lines, array
indices are only incremented when such lines are found.  A separate
hash ([[%chunks]]) stores, for each unique name, a list of all
definitions' text array start and end indicies.

When duplicating a definition, the original file and line location are
needed.  When parsing a reference, the original file and line location
may be needed for error messages.  Rather than store these in separate
locations for each, a couple of arrays are added ([[@textfile]],
[[@textline]]), and the file and line for any particular definition or
usage text array element is stored in the side arrays with the same
index.  There is no need to assign values to unused indicies, since
they will never be referenced and perl doesn't complain.

<<[[nt-parm]] local definitions>>=
my (@notext, @textfile, @textline, %chunks);
@

<<Gather code chunks from NoWeb pipeline>>=
my $lineno = 1; my $file = '<stdin>';
my ($codeline, $codefile, $curchunk);
push @notext, '';
while(<STDIN>) {
  print $_;
   if(/^\@begin code( |$)/) {
    $codeline = $lineno;
    $codefile = $file;
    push @notext, $_;
  } elsif(/^\@defn (.*)$/) {
    unless($codeline) {
      print STDERR "$file:$lineno: invalid chunk syntax\n";
      exit 1;
    }
    if(substr($1, 0, 1) eq '@') {
      print STDERR "$file:$lineno: ";
      print STDERR "initial @ is reserved for parameter names\n";
      print "\@nl\n\@end code\n"; # prevent malformed code messages
      print "\@fatal invalid chunk name\n";
      exit 1;
    }
    $curchunk = $1;
    $notext[$#notext] .= $_;
    $textfile[$#notext] = $file;
    $textline[$#notext] = $lineno;
    <<Store [[$curchunk]] info>>
    push @notext, '';
  } elsif(/^\@end code( |$)/) {
    unless($curchunk) {
      print STDERR "$file:$lineno: invalid chunk syntax\n";
      exit 1;
    }
    $notext[$#notext] .= $_;
    <<Finish off [[$curchunk]]>>
    push @notext, '';
    $codeline = $codefile = $curchunk = undef;
  } elsif(/^\@use .*$/) {
    if($curchunk) {
      push @notext, $_;
      $textfile[$#notext] = $file;
      $textline[$#notext] = $lineno;
      push @notext, '';
    }
  } elsif(/^\@fatal( |$)/) {
    exit 1;
  } elsif(/^\@(index |)nl( |$)/) {
    $lineno++;
    $notext[$#notext] .= $_ if $codeline;
  } elsif(/^\@file (.*)$/) {
    $file = $1;
    $lineno = 1;
    $notext[$#notext] .= $_ if $codeline;
  } elsif(/^\@line (.*)$/) {
    $lineno = $1 - 1;
    $notext[$#notext] .= $_ if $codeline;
  } else {
    $notext[$#notext] .= $_ if $codeline;
  }
}
@

The information stored for each chunk definition is the array index of
the starting and ending line.  This is stored as two array entries for
each chunk.

<<Store [[$curchunk]] info>>=
$chunks{$curchunk} = [] if not $chunks{$curchunk};
push @{$chunks{$curchunk}}, $#notext;
@

<<Finish off [[$curchunk]]>>=
push @{$chunks{$curchunk}}, $#notext;
@

Since normal code syntax is used for parameter values, special care
must be taken to distinguish them.  This is done by first scanning for
a chunk which exactly matches the reference.  If this is not found,
parameterized functions are searched, with the most explicit one
matching.  For the second step, a filter is applied to replace in-line
code and parameter definitions with placeholders to create the key for
a hash of stripped names ([[%parmchunks]]).  Each hash entry is an
list of definition names with the same key.  This reduces the number
of chunk names that need to be checked every time a potential
expansion is found.  Note that the list of names is in the form of a
hash itself; this is so duplicates can be removed without thinking;
the actual array is obtained with the [[keys]] function.

<<[[nt-parm]] local definitions>>=
my %parmchunks;
<<[[strip_chunkname]]>>
@

<<[[strip_chunkname]]>>=
# note: $parm_re's first capture group is the parameter
#       $parm_re's second cpature group is for recursion (ignore!)
my $parm_re = '(\(\@[^)]*\)|(?<!@)\[\[((?:[^][]|\[(?-1)\])*)\]\])';
sub strip_chunkname($)
{
  my $n = shift;
  $n =~ s/$parm_re/(@)/g;
  return $n;
}
@

<<Store [[$curchunk]] info>>=
my $strip = strip_chunkname $curchunk;
$parmchunks{$strip} = {} if not $parmchunks{$strip};
${$parmchunks{$strip}}{$curchunk} = 1;
@

Once all has been collected, the duplicated chunks can be dumped. This
is done by iterating through the array, looking for [[@use]]es.  Any
[[@use]] which is already present in [[%chunks]] is left alone.
Otherwise, if there is a match to a parameterized name (i.e. an entry
in [[%parmchunks]] for the stripped name), the best such name is found
and dumped using the use-name.

<<Mangle and dump pipeline>>=
for(my $i = 0; $i <= $#notext; $i++) {
  my $u = $notext[$i];
  next if $u !~ /^\@use (.*)$/;
  my $curchunk = $1;
  next if $chunks{$curchunk};
  my ($best, %best_parms) = find_best_def(idx_to_loc($i), $curchunk);
  next unless $best;
  <<Dump best definition match for [[$curchunk]]>>
}
@

<<[[nt-parm]] local definitions>>=
<<[[find_best_def]]>>

sub idx_to_loc($) {
  my $idx = $_[0];
  return "$textfile[$idx]:$textline[$idx]: ";
}
@

<<[[find_best_def]]>>=
sub find_best_def($$) {
  my ($loc, $curchunk) = @_;
  my $pchunks = $parmchunks{strip_chunkname $curchunk};
  return if not $pchunks;
  <<Find best definition match for [[$curchunk]]>>
}
@

Each possible expansion is checked, keeping the best.  While it's
doing that, since it already has the parameter names and their values
parsed out, a symbol table is built for the parameters.  As you may
have noticed above, the symbol table is returned along with the
matched chunk name.

<<Find best definition match for [[$curchunk]]>>=
my ($best, %best_parms);
<<Prepare for finding best definition match>>
PCHUNK: foreach my $may (keys %$pchunks) {
  my %may_parms;
  <<Check [[$may]] and collect parameter defs into [[%may_parms]]>>
  <<[[next PCHUNK]] if [[$may]] is not best>>
  $best = $may;
  %best_parms = (%may_parms);
  <<Save additional best info about [[$may]]>>
}
<<Finish up after finding best definition match>>
return ($best, %best_parms);
@

Checking for a match involves simultaneously iterating over the replaced
portions of the names.  If the replaced portion of both names matches,
it's considered a match (even if both are in the parameter definition
form, although perhaps that should be an error).  If they do not
match exactly, they still match if the definition side is in parameter
definition form, and the usage side is in literal code text form.

<<Check [[$may]] and collect parameter defs into [[%may_parms]]>>=
<<Prepare to check if definition matches>>
my $mayrest = $may;
my $currest = $curchunk;
while($mayrest =~ /$parm_re(.*)/) {
  <<Prepare for resolving ambiguity per match>>
  my $mayp = $1;
  $mayrest = $3;
  $currest =~ /$parm_re(.*)/;
  my $curp = $1;
  $currest = $3;
  next if $curp eq $mayp;
  next PCHUNK if substr($mayp, 0, 1) eq "[" ||
                 substr($curp, 0, 1) eq "(";
  <<Store parameter [[$curp]] in [[$mayp]]>>
}
@

<<Store parameter [[$curp]] in [[$mayp]]>>=
$may_parms{substr($mayp, 1, -1)} = substr($curp, 2, -2);
@

To resolve ambiguity, the name with the fewest substitutions is
retained.

<<Prepare for finding best definition match>>=
my $best_len = length $curchunk; # larger than all possible lengths
@

<<Prepare to check if definition matches>>=
my $len = 0;
@

<<Store parameter [[$curp]] in [[$mayp]]>>=
$len++;
@

<<[[next PCHUNK]] if [[$may]] is not best>>=
next PCHUNK if $len > $best_len;
@

<<Save additional best info about [[$may]]>>=
$best_len = $len;
@

If two names have an equal number of substitutions, the one which has
in-line code at the first position where the two differ is chosen, and
a warning is issued.  If two names have an equal number of
substitutions, and all are in the same places, then there is an
unresolvable ambiguity, leading to error exit.

<<Prepare for finding best definition match>>=
my @best_parms_loc;
my (@ambig, $bad_ambig);
@

<<Prepare to check if definition matches>>=
my @may_parms_loc;
my $parm_loc = 0;
@

<<Prepare for resolving ambiguity per match>>=
$parm_loc++;
@

<<Store parameter [[$curp]] in [[$mayp]]>>=
push @may_parms_loc, $parm_loc;
@

<<[[next PCHUNK]] if [[$may]] is not best>>=
if($len == $best_len) {
  $ambig[0] = $best if $#ambig == 0;
  push @ambig, $may;
  my $i;
  for($i = 0; $i <= $#may_parms_loc; $i++) {
    next PCHUNK if $may_parms_loc[$i] < $best_parms_loc[$i];
    last if $may_parms_loc[$i] > $best_parms_loc[$i];
  }
  $bad_ambig = 1 if $i == $#may_parms_loc + 1;
  if($bad_ambig) {
    $best = undef;
    next PCHUNK;
  }
} else {
  @ambig = undef;
  $bad_ambig = undef;
}
@

<<Save additional best info about [[$may]]>>=
@best_parms_loc = (@may_parms_loc);
@

<<Finish up after finding best definition match>>=
if($#ambig > 0) {
  print STDERR $loc;
  print STDERR "fatal: unresolvable " if $bad_ambig;
  print STDERR "ambiguous expansion of @<<$curchunk@>>:\n";
  foreach my $may (@ambig) {
    print STDERR "  @<<$may@>>";
    print STDERR " (chosen)" if $may eq $best;
    print STDERR "\n";
  }
  if($bad_ambig) {
    print "\@fatal ambiguous expansion\n";
    exit 1;
  }
}
@

Technically, there are hidden [[@use]] references within the reference
name, in the form of explicitly passed down parameters.  At the top
level, these should always generate errors, since no parameters have
been defined yet.  However, since we're dumping chunks whether they
are used or not, the error cannot be printed.  I suppose emitting an
explicit [[@use]] just after the reference would cause notangle to
emit an error message, but instead, these are just left as is.  Some
of these references are in the main text anyway, and it's too late to
make changes to that since it's already been dumped.

<<Dump best definition match for [[$curchunk]]>>=
# since we're not notangle, we have to expand every single chunk
# so raising an error on unknown parm is not possible
# for now, just go ahead and leave unexpanded
#foreach my $v (values %best_parms) {
#  foreach my $bad_val ($v =~ /@<<(@.*?)(?<!@)>>)/) {
#
#    print "$textfile[$i]:$textline[$i]: " .
#          "undefined parameter $bad_val\n";
#  }
#}
@

While a chunk is dumped, any references within the dumped text must be
checked as well.  Thus, instead of printing the chunk immediately, it
is accumulated into a string, and dumped when finished.  References'
dumped defnitions are recursively gathered and then appended to the
final return string.

<<Dump best definition match for [[$curchunk]]>>=
print dump_def($best, $curchunk, %best_parms);
@

<<[[nt-parm]] local definitions>>=
sub dump_def($$%) {
  my ($old, $new, %parms) = @_;
  my ($ret, $subdefs);
  <<Collect [[$old]] as [[$new]] with [[%parms]] into [[$ret]]>>
  return $ret . $subdefs;
}
@

Before dumping the definition, though, if it has already been dumped,
it should be skipped.  Above, the dumping was explicitly skipped if
the chunk was already defined, so the same check is used within
[[dump_def]], and those checks are enabled by defining a dummy chunk.

<<Collect [[$old]] as [[$new]] with [[%parms]] into [[$ret]]>>=
$chunks{$new} = [];
@

The definition text to be dumped consists of all chunks for the
[[$old]] definition.  Before each chunk's text emission, a [[@file]]
and [[@line]] directive is emitted, to keep [[-L]] working.  The first
[[$notext]] entry for every chunk definition is the [[@defn]] line
itself and needs to be processed separately.  It is just dumped as is
with the old name replaced by the new name.  Other than that, only the
[[@use]] lines need special processing.

<<Collect [[$old]] as [[$new]] with [[%parms]] into [[$ret]]>>=
my $chunk = $chunks{$old};
for(my $c = 0; $c <= $#$chunk; $c += 2) {
  my $i = $$chunk[$c];
  my $last = $$chunk[$c + 1];
  $ret .= "\@file $textfile[$i]\n\@line " . ($textline[$i] + 1) . "\n";
  $ret .= substr($notext[$i], 0, -(length($old) + 1)) . $new . "\n";
  for($i++; $i <= $last; $i++) {
    my $t = $notext[$i];
    if($t !~ /^\@use (.*)$/) {
      $ret .= $t;
    } else {
      <<Transform and add [[@use]] [[$1]] to [[$ret]]>>
    }
  }
}
@

Any [[@use]] which refers to a parameter is replaced immediately by
the literal parameter text value.  Due to the syntax of noweb chunk
names, there is never a newline in the value, so a single [[@text]] is
generated.

To dump a chunk, any [[@use]] references within the chunk must be
checked.  Those which refer to a parameter are replaced by the
parameter's value.  Those which refer to a chunk with parameter
expansions cause that chunk to be duplicated, as well, with the root
chunk name as a prefix, separated from the real name by something that
is unlikely to occur in real names ([[@<<@>>]]).  The current set of
parameters is tracked througout this process, so that parameter
references (even within parameter values) are properly expanded.
Naturally, the top-level reference can't use a parameter reference,
since no parameters are defined yet.

<<Transform and add [[@use]] [[$1]] to [[$ret]]>>=
if(substr($1, 0, 1) eq '@') {
  if($parms{$1}) {
    $ret .= "\@text $parms{$1}\n";
  } else {
    # again, we're not notangle, so can't raise errors here
    #print STDERR "$textfile[$i]:$textline[$i]: " .
    #             "undefined parameter @<<$1@>>\n" unless $parms{$1};
    # but we can force notangle to raise an error:
    $ret .= $t;
  }
@

Otherwise, if the chunk reference requires parameter processing, it
needs to be handled pretty much the same as in the main loop, except
that instead of (not) raising errors for parameter references within
values, they must be expanded.  If a parameter expansion results in a
more explicit match to a definition, that more explicit match is used
instead.

Note that exact matches give ``best'' definitions as well, so this
code will handle unparameterized calls as well, skipping the reference
substitution due to an empty [[%best_parms]].

<<Transform and add [[@use]] [[$1]] to [[$ret]]>>=
} else {
  my $new_chunk = $1;
  my ($best, %best_parms) = find_best_def(idx_to_loc($i), $new_chunk);
  next if not $best;
  <<Handle dump of [[$best]]>>
}
@

<<Handle dump of [[$best]]>>=
($new_chunk, $best, %best_parms) = recheck_best(idx_to_loc($i), $new_chunk,
                                                $best, \%best_parms, \%parms);
# add new parms to global set of parms for recursive call
my %new_parms = (%parms, %best_parms);
@

<<[[nt-parm]] local definitions>>=
# substitute parameter refs in chunk name and maybe find new best match
sub recheck_best($$$$$) {
  my ($err_loc, $new_chunk, $best, $best_parms, $parms) = @_;
  my $parms_changed;
  foreach my $p (keys %$best_parms) {
    my $v = $$best_parms{$p};
    my $newv = '';
    my $vrest = $v;
    while($vrest =~ /(.*?)@<<(@.*?)(?<!@)>>(.*)/) {
      $newv .= $1 . $$parms{$2};
      $vrest = $3;
      # once again, can't print error because we're not notangle
      #print STDERR "$textfile[$i]:$textline[$i]: " .
      #             "undefined parameter @<<$2@>>\n" if not $parms{$2};
      # instead, silently ignore/replace with blanks
    }
    $newv .= $vrest;
    if($newv ne $v) {
      $$best_parms{$p} = $newv; # not needed if find_best_def used below
      $new_chunk =~ s/(?<!@)\[\[\Q$v\E\]\]/[[$newv]]/;
      $parms_changed = 1;
    }
  }
  # find better match if var replacements were made
  if($parms_changed) {
    my %new_best_parms;
    ($best, %new_best_parms) = find_best_def($err_loc, $new_chunk);
    $best_parms = \%new_best_parms;
  }
  return ($new_chunk, $best, %$best_parms);
}
@

Parameters are implicitly inherited by expanded chunks.  This changes
the text of those expanded chunks if they reference the implicitly
defined parameters, and requires that they be dumped as well.  Their
name needs to change to avoid conflict with existing symbols, in a
consistent way so that they do not need to be dumped more than once.
For now, this is done by prepending the root chunk name defining the
parameter it (or one of its expanded chunks) uses, separated from the
name by something that would be hard to add to a real chunk name:
$@<<>>$.

Referenced chunks will enter this code as well, adding their own name
to the already long chunk name.  This could be prevented by passing in
a prefix, and only updating that prefix when a parameterized chunk
name is encountered whose parameters are specifically referenced.
Maybe in a future revision.  Another way to shorten these names would
be to use short random garbage as the prefix instead.   That might
make sharing chunks harder, though.

<<Handle dump of [[$best]]>>=
# add w/ uniquifier prefix if implicit parms referenced
my $has_ref = has_implref($best, \%new_parms, \%best_parms);
my $sub_name = $has_ref ? $new . '@<<>>' . $new_chunk : $new_chunk;
$ret .= "\@use $sub_name\n";
# skip if already there
next if $chunks{$sub_name};
# skip if plain reference with no parm refs
next if $sub_name eq $best;
$subdefs .= dump_def($best, $sub_name, %new_parms);
@

Finding references to implicitly defined parameters requires scanning
every [[@use]] of a parameter for a definition in the global table
which is not in the local table.  Any non-parameter [[@use]] must also
be scanned, recursively, assigning symbol values if that [[@use]] is a
parameterized reference.

<<[[nt-parm]] local definitions>>=
sub has_implref($$$) {
  my ($chunkparts, $impl_parms, $direct_parms) = @_;
  $chunkparts = $chunks{$chunkparts};
  for(my $i = 0; $i <= $#$chunkparts; $i += 2) {
    my $low = $$chunkparts[$i];
    my $high = $$chunkparts[$i + 1];
    for(;$low <= $high; $low++) {
      if($notext[$low] =~ /^\@use (.*)$/) {
        <<Check if [[$1]] is an implicit ref>>
      }
    }
  }
  return 0;
}
@

If it is in either symbol table, it is definitely a parameter, so
instead of checking the syntax, a lookup success is acted on
immediately.  On the other hand, if it is a parameter reference, and
both lookups failed, it is ignored.

<<Check if [[$1]] is an implicit ref>>=
next if $$direct_parms{$1};
return 1 if $$impl_parms{$1};
next if substr($1, 0, 1) eq '@';
@

For full chunk references, a (possibly parameterized) match is looked
up.  Any implicit references in parameter text must be detected as well.

<<Check if [[$1]] is an implicit ref>>=
my $orig = $1;
my ($best, %best_parms) = find_best_def(idx_to_loc($low), $orig);
next if not $best;
foreach my $p (keys %best_parms) {
  my $vrest = $best_parms{$p};
  while($vrest =~ /@<<(@.*?)(?<!@)>>(.*)/) {
    return 1 if $$impl_parms{$1} && not $$direct_parms{$1};
    $vrest = $2;
  }
}
($orig, $best, %best_parms) = recheck_best(idx_to_loc($i), $orig, $best,
                                           \%best_parms, $impl_parms);
my %new_impl = (%$impl_parms, %best_parms);
return 1 if has_implref($best, \%new_impl, \%best_parms);
@

\section{Weaving}

These enhancements also require changes to the weavers.  No particular
effort will be made to typeset things nicely.  Parameter references
should be typeset as chunk references, but without the links (where
would they link to?).  To do that, they need to be hidden from the
indexer, and unhidden after the indexer.  Likewise, to get cross
references right, references to parameterized chunks with actual
parameters need to be converted to the definition format for the
indexer, and then changed back afterwards.  These tasks can be
accomplished by two filters:  one for before indexing, and one for
after.

%\lstset{language=perl}
<<nw-parm-preidx>>=
<<Common Perl Prefix>>

@

<<nw-parm-postidx>>=
<<Common Perl Prefix>>

@

The pre-index filter needs to know how to interpret chunk references
with in-line code:  either as in-line code, or as macro parameters.
The only way to do this is to know the names of all chunks.  Since
weaving does not require all tangling inputs, but this particular task
does require them, any inputs not included in the weaving process must
be specified on the filter's command line.  While it might be nice to
use the standard markup tool for this, it is not present in noweb 3.
Instead, the file is parsed directly, with a very limited view of what
constitutes the start of a chunk.  This probably needs improvement.

Much like the tangler's reader, each definition is placed into two
arrays:  one indexed by its real name, and one indexed by its name
with all parameter definitions and references stripped out.  That way,
finding the actual chunk to use for a macro reference is easier.

<<nw-parm-preidx>>=
<<[[strip_chunkname]]>>

my (%chunks, %parmchunks);

foreach my $a (@ARGV) {
#  open(my $fh, "markup $a|");
  open(my $fh, "$a");
  while(<$fh>) {
#    next unless(m/^\@defn (.*)$/);
    next unless(m/^@<<(.*)@>>=$/);
    $chunks{$1} = 1;
    my $s = strip_chunkname($1);
    $parmchunks{$s} = {} if not $parmchunks{$s};
    ${$parmchunks{$s}}{$1} = 1;
  }
  close $fh;
}
@

The filter process needs to scan the file more than once.  The first
time, it gathers definitions just like it did for the command-line
arguments.  For convenience, the file is just read into an array of
plain text lines for processing.

<<nw-parm-preidx>>=
my @file = <STDIN>;
foreach my $l (@file) {
  next unless($l =~ m/^\@defn (.*)$/);
  $chunks{$1} = 1;
  my $s = strip_chunkname($1);
  $parmchunks{$s} = {} if not $parmchunks{$s};
  ${$parmchunks{$s}}{$1} = 1;
}
@

For the second pass, an attempt is made to match a chunk reference
with a definition.  If it matches, and requires parameter expansion to
do so, its name is replaced with the parameterized definition, and its
old name is saved using [[@nwparmcall]].  The matching method is
copied from the tangler, with minor differences.  Line and file
information are not tracked by this filter, so the location string is 
always blank.  Also, since a standalone chunk does not have parameter
values, the specialization performed after paramter expansion in chunk
names can't be done.  Unfortunately, there is also no special link
between a parameterized chunk and all of its potential specializations.

Parameter references are simply hidden by renaming them to
[[@nwparmuse]].

As a special hack, in order to highlight parameters better, an extra
set of square brackets is placed around them.  This repeats some of
the work that [[find_best_def]] does, but that's not too terrible.

<<nw-parm-preidx>>=
<<[[find_best_def]]>>

foreach my $l (@file) {
  if($l =~ /^\@use ([^@].*\[\[.*\]\].*)$/) {
    my ($best,) = find_best_def('', $1);
    if($best and $best ne $1) {
      my $cur = '';
      my ($b, $c) = ($best, $1);
      while($b =~  /$parm_re(.*)/) {
        my $bp = $1;
        $b = $3;
        $c =~ /^(.*?)$parm_re(.*)/;
        my $cp = $2;
        $c = $4;
	$cur .= $1;
	if($cp eq $bp) {
	  $cur .= $cp;
	} else {
	  $cur .= '[[' . $cp . ']]';
	}
      }
      $cur .= $c;
      print "\@nwparmcall $cur\n\@use $best\n";
    } else {
      print $l;
    }
  } else {
    $l =~ s/^\@use \@/\@nwparmuse \@/;
    print $l;
  }
}
@

For the third pass, done after the index, the above-added tags are
reverted.

<<nw-parm-postidx>>=
my $nwparmcall;

while(<STDIN>) {
  if(/^\@nwparmcall (.*)$/) {
    $nwparmcall = $1;
  } elsif(/^\@use / and $nwparmcall) {
    print "\@use $nwparmcall\n";
    $nwparmcall = undef;
  } else {
    s/^\@nwparmuse /\@use /;
    print "$_";
  }
}
@

\section{Other}

This is not the end of it:  [[noroots]] (noweb-2 only) needs changes
as well.  There is no reason to retain the pipeline for this tool, so
it could be standalone and not depend on the markup parser.  However,
keeping the parsing to the one official parser might be a good idea.
The [[noroots]] script is not a simple pipeline, though:  it includes
the entire ``backend'' in-line.  To make a replacement script, the
library location is lifted using a trick filter in notangle.

The procedure is the same as standard [[noroots]], except that after
collecting all usages, a pass is made over the usage array to add
parameterized usages.

<<noroots-parm>>=
<<Common Perl Prefix>>

my $LIB = `notangle -filter 'echo \$LIB >&3' /dev/null 2>/dev/null 3>&1`;
chomp $LIB;

my (%chunks, %parmchunks, %use);

open(my $f, "-|", "$LIB/markup", @ARGV);

<<[[strip_chunkname]]>>

while(<$f>) {
  if(/^\@quote$/) {
    while(<$f>) {
      last if(/\@endquote$/);
    }
  } elsif(/^\@defn (.*)$/) {
    $chunks{$1} = 1;
    my $s = strip_chunkname($1);
    $parmchunks{$s} = {} if not $parmchunks{$s};
    ${$parmchunks{$s}}{$1} = 1;
  } elsif(/^\@use (.*)$/) {
    $use{$1} = 1;
  }
}

<<[[find_best_def]]>>

for my $u (keys %use) {
  if(substr($b, 0, 1) ne '@') {
    my ($b,) = find_best_def('', $u);
    $use{$b} = 1 if $b;
  }
}
@

One major problem is that finding a new match after parameter
expansion is no longer done.  The only way to check for these is to
check each root, expanding any parameter references, and marking any
newly used definitions.  This would need to be done in two passes:
first to cover unparameterized roots, and then to cover any remaining
parameterized roots.  Thus the entire code above would need to be
rewritten.  Instead, a simple hack is performed: for any usage of a
parameterizable chunk with a passed-on parameter, all possible
specializations of that parameter are marked used as well.  This
(along with the previous loop) may end up marking more than necessary,
but it's probably good enough for a program that isn't really
officially supported, anyway.

<<noroots-parm>>=
for my $u (keys %use) {
  next if rindex($u, '@<<@') < 2;  # needs at least one parm ref in code
  my $pchunks = $parmchunks{strip_chunkname $u};
  next if not $pchunks ||
       (scalar keys %$pchunks) == 0 ; # needs possible resolutions
  my ($b, %bp) = find_best_def('', $u);
  next if $b eq $u; # needs to resolve without specialization
  # find possible parameters with parameter expansion
  my %vars;
  foreach my $v (keys %bp) {
    $vars{$v} = 1 if index($bp{$v}, '@<<@') >= 0;
  }
  next if (scalar keys %vars) == 0;
  # map vars to var positions
  my @vpos;
  my $brest = $b;
  while($brest =~ /$parm_re(.*)/) {
    my $bp = $1;
    $brest = $3;
    push @vpos, substr($bp, 0, 1) eq '(' && $vars{substr($bp, 1, -1)};
  }
  # for each possible resolution, allow anything at $u's var positions
  # also, allow mapping of any parm to any code text
  foreach my $pc (keys %$pchunks) {
    next if $pc eq $b;
    my $i = 0;
    my $urest = $u;
    my $prest = $pc;
    my $matched = 1;
    while($prest =~ /$parm_re(.*)/) {
      my $bp = $1;
      $prest = $3;
      $urest =~ /$parm_re(.*)/;
      my $up = $1;
      $urest = $3;
      if(substr($bp, 0, 1) eq '[') {
        $matched = $vpos[$i] || $bp eq $up;
      } else {
        $matched = substr($up, 0, 1) eq '[' || $bp eq $up;
      }
      last if not $matched;
      $i++;
    }
    $use{$pc} = 1 if $matched;
  }
}
@

Once that's been taken care of, the roots can be printed.

<<noroots-parm>>=
for my $d (keys %chunks) {
  print "@<<$d@>>\n" unless $use{$d};
}
@

\section{Usage}

In summary, to use this, see the introduction for syntax.  Extract the
following four chunks from this document, make them executable (or
always prefix them with the path to perl in filter command lines), and
use as described:

\begin{itemize}
\item [[nt-parm]] --- always use this as a filter when tangling.
\item [[nw-parm-preidx]] --- always use this as a filter when weaving,
before indexing (or implicit indexing, such [[-x]], [[-index]], etc.).
\item [[nw-parm-postidx]] --- always use this as a filter when
weaving, after indexing (or implicit indexing).  If no indexing is
done at all, use both of these filters with nothing in between.
\item [[noroots-parm]] --- use this in place of [[noroots]].
\end{itemize}

For example:

\begin{verbatim}
notangle -filter ./nt-parm -R'myroot' mystuff.nw > out
noweave -filter ./nw-parm-preidx -index \
        -filter ./nw-parm-postidx mystuff.nw > mystuff.tex
\end{verbatim}

If you are weaving a file that is meant to be tangled together with
other files, those other files need to be given on the
[[nw-parm-preidx]] command line.  Repeating the main input file is
harmless.  For example, if [[x.nw]] and [[y.nw]] are normally tangled
together, but weaved separately:

\begin{verbatim}
notangle -filter ./nt-parm -R'myroot' x.nw y.nw > out
noweave -filter "./nw-parm-preidx y.nw" -index \
        -filter ./nw-parm-postidx x.nw > x.tex
noweave -filter "./nw-parm-preidx x.nw" -index \
        -filter ./nw-parm-postidx y.nw > y.tex
\end{verbatim}

\end{document}
